{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 2: Audit and Fix a Broken AI Compliance Plan (Colab Edition)\n",
        "\n",
        "This notebook walks you through auditing a broken AI compliance plan and rewriting it using responsible AI practices. You'll:\n",
        "\n",
        "- Analyze a flawed AI risk plan\n",
        "- Detect compliance violations using Python\n",
        "- Recommend best practices for each violation\n",
        "- Rewrite the compliance document in a structured format (Markdown)\n",
        "- Save and (optionally) download the improved plan\n",
        "\n",
        "_Adapted for Google Colab from the original Lab 2 guide._\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to use this notebook in Google Colab\n",
        "1. Run each cell from top to bottom.\n",
        "2. The notebook will create a `broken_compliance_plan.md`, generate suggested fixes, and produce a `fixed_ai_compliance_plan.md` file.\n",
        "3. Use the **Download** cell to download the revised plan to your machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost/"
        },
        "id": "setup-imports"
      },
      "outputs": [],
      "source": [
        "# (Optional) Basic setup\n",
        "from datetime import datetime\n",
        "print('Environment ready. Python version detected.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Define the flawed compliance plan\n",
        "We simulate a broken AI compliance checklist and preview it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define-broken"
      },
      "outputs": [],
      "source": [
        "# Define broken compliance entries\n",
        "broken_checks = [\n",
        "    \"Data is collected without user consent\",\n",
        "    \"Bias testing skipped due to time constraints\",\n",
        "    \"No logging of predictions\"\n",
        "]\n",
        "\n",
        "print(\"Detected Compliance Issues:\\n\")\n",
        "for item in broken_checks:\n",
        "    print(f\"[ ] Issue Found: {item}\")\n",
        "\n",
        "# (Optional) Save the broken plan to a markdown file for reference\n",
        "with open('broken_compliance_plan.md', 'w', encoding='utf-8') as f:\n",
        "    for item in broken_checks:\n",
        "        f.write(f\"- {item}\\n\")\n",
        "print('\\nSaved: broken_compliance_plan.md')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Suggest best practice fixes\n",
        "We map each issue to a recommended fix and assign a responsible AI domain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suggest-fixes"
      },
      "outputs": [],
      "source": [
        "# Map issues to industry best practices\n",
        "fixes = {\n",
        "    \"Data is collected without user consent\": {\n",
        "        \"fix\": \"Always collect explicit, informed user consent before storing or processing data.\",\n",
        "        \"domain\": \"Legal\"\n",
        "    },\n",
        "    \"Bias testing skipped due to time constraints\": {\n",
        "        \"fix\": \"Automate bias checks in CI/CD pipelines and enforce pre-deployment fairness gates.\",\n",
        "        \"domain\": \"Ethical\"\n",
        "    },\n",
        "    \"No logging of predictions\": {\n",
        "        \"fix\": \"Log predictions with user anonymization and retain audit trails for accountability.\",\n",
        "        \"domain\": \"Operational\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\nSuggested Fixes:\\n\")\n",
        "for issue, data in fixes.items():\n",
        "    print(f\"Issue: {issue}\\nFix: {data['fix']}\\nDomain: {data['domain']}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Rewrite and save the fixed compliance plan\n",
        "We generate a structured Markdown document consolidating the metadata and recommended fixes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rewrite-save"
      },
      "outputs": [],
      "source": [
        "# Metadata for the revised plan\n",
        "metadata = {\n",
        "    \"plan_owner\": \"Compliance Team\",\n",
        "    \"generated_by\": \"Colab Notebook (Lab 2)\",\n",
        "    \"version\": \"1.0\",\n",
        "    \"date_created\": datetime.now().strftime('%Y-%m-%d')\n",
        "}\n",
        "\n",
        "# Write the revised plan to a markdown file\n",
        "out_path = 'fixed_ai_compliance_plan.md'\n",
        "with open(out_path, 'w', encoding='utf-8') as f:\n",
        "    f.write('# Revised AI Compliance Plan\\n\\n')\n",
        "    f.write('## Metadata\\n')\n",
        "    for key, value in metadata.items():\n",
        "        f.write(f\"- **{key}**: {value}\\n\")\n",
        "    f.write('\\n---\\n')\n",
        "\n",
        "    for issue, data in fixes.items():\n",
        "        f.write(f\"### Issue\\n{issue}\\n\\n\")\n",
        "        f.write(f\"**Recommended Fix:** {data['fix']}\\n\\n\")\n",
        "        f.write(f\"**Responsible AI Domain:** {data['domain']}\\n\\n\")\n",
        "        f.write('---\\n')\n",
        "\n",
        "print(f\"Compliance plan successfully saved to '{out_path}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Preview & (Optionally) Download the Revised Plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preview-download"
      },
      "outputs": [],
      "source": [
        "# Preview the first ~80 lines of the revised plan\n",
        "with open('fixed_ai_compliance_plan.md', 'r', encoding='utf-8') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i > 80:\n",
        "            break\n",
        "        print(line.rstrip())\n",
        "\n",
        "# If running in Google Colab, uncomment the lines below to download the file\n",
        "# from google.colab import files\n",
        "# files.download('fixed_ai_compliance_plan.md')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Review (Knowledge Check)\n",
        "1. What kind of risk is posed by missing consent from users in an AI system?\n",
        "    - A. Data risk  \n",
        "    - B. **Legal risk**  \n",
        "    - C. Technical risk  \n",
        "    - D. Ethical risk  \n",
        "\n",
        "2. Why should audit logs be maintained in AI systems?\n",
        "    - A. To improve model accuracy  \n",
        "    - B. To increase model training speed  \n",
        "    - C. **To support traceability and compliance**  \n",
        "    - D. To reduce model size  \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}